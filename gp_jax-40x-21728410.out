
RUNNING: adjoints

Namespace(name='adjoints', seed=1, num_data=40000, rank_precon=500, num_partitions=200, num_matvecs=10, num_samples=5, num_epochs=100)

Predicting ~ 0.2980232238769531 GB of memory

Train: (36000, 3) (36000,)
Test: (4000, 3) (4000,)

Runtime (value): 2.4172056573443115
Runtime (value-and-gradient): 10.33825933886692

A-priori CG error: 9.854452e-08
A-priori SLQ std (rel): 0.07968551
A-priori RMSE: 0.5644587
A-priori NLL: 1.1657444



RMSE: 0.1743363
NLL: 1.0015835

[KeOps] Compiling cuda jit compiler engine ... OK
[pyKeOps] Compiling nvrtc binder for python ... OK

RUNNING: gpytorch

Namespace(name='gpytorch', seed=1, num_data=40000, rank_precon=500, num_matvecs=10, num_samples=5, num_epochs=100, cg_tol=1.0)
[KeOps] Generating code for Sum_Reduction reduction (with parameters 0) of formula ((d*Sqrt(Sum((a-b)**2)+c)+1)*Exp(e*Sqrt(Sum((a-b)**2)+c)))*f with a=Var(0,3,0), b=Var(1,3,1), c=Var(2,1,2), d=Var(3,1,2), e=Var(4,1,2), f=Var(5,6,1) ... OK
[KeOps] Generating code for Sum_Reduction reduction (with parameters 0) of formula (Rsqrt(Sum((a-b)**2)+c)*((a-b)*(d*(g|f)+e*((g|f)*(d*Sqrt(Sum((a-b)**2)+c)+1)))))*Exp(e*Sqrt(Sum((a-b)**2)+c)) with a=Var(0,3,0), b=Var(1,3,1), c=Var(2,1,2), d=Var(3,1,2), e=Var(4,1,2), f=Var(5,6,1), g=Var(6,6,0) ... OK
[KeOps] Generating code for Sum_Reduction reduction (with parameters 1) of formula -((Rsqrt(Sum((a-b)**2)+c)*((a-b)*(d*(g|f)+e*((g|f)*(d*Sqrt(Sum((a-b)**2)+c)+1)))))*Exp(e*Sqrt(Sum((a-b)**2)+c))) with a=Var(0,3,0), b=Var(1,3,1), c=Var(2,1,2), d=Var(3,1,2), e=Var(4,1,2), f=Var(5,6,1), g=Var(6,6,0) ... OK
[KeOps] Generating code for Sum_Reduction reduction (with parameters 0) of formula ((d*Sqrt(Sum((a-b)**2)+c)+1)*f)*Exp(e*Sqrt(Sum((a-b)**2)+c)) with a=Var(0,3,0), b=Var(1,3,1), c=Var(2,1,2), d=Var(3,1,2), e=Var(4,1,2), f=Var(5,1,1) ... OK

RMSE: tensor(0.1722, device='cuda:0')
NLL: (todo)



RUNNING: gpytorch3x

Namespace(name='gpytorch3x', seed=1, num_data=40000, rank_precon=500, num_matvecs=30, num_samples=15, num_epochs=100, cg_tol=0.01)
[KeOps] Generating code for Sum_Reduction reduction (with parameters 0) of formula ((d*Sqrt(Sum((a-b)**2)+c)+1)*Exp(e*Sqrt(Sum((a-b)**2)+c)))*f with a=Var(0,3,0), b=Var(1,3,1), c=Var(2,1,2), d=Var(3,1,2), e=Var(4,1,2), f=Var(5,16,1) ... OK
[KeOps] Generating code for Sum_Reduction reduction (with parameters 0) of formula (Rsqrt(Sum((a-b)**2)+c)*((a-b)*(d*(g|f)+e*((g|f)*(d*Sqrt(Sum((a-b)**2)+c)+1)))))*Exp(e*Sqrt(Sum((a-b)**2)+c)) with a=Var(0,3,0), b=Var(1,3,1), c=Var(2,1,2), d=Var(3,1,2), e=Var(4,1,2), f=Var(5,16,1), g=Var(6,16,0) ... OK
[KeOps] Generating code for Sum_Reduction reduction (with parameters 1) of formula -((Rsqrt(Sum((a-b)**2)+c)*((a-b)*(d*(g|f)+e*((g|f)*(d*Sqrt(Sum((a-b)**2)+c)+1)))))*Exp(e*Sqrt(Sum((a-b)**2)+c))) with a=Var(0,3,0), b=Var(1,3,1), c=Var(2,1,2), d=Var(3,1,2), e=Var(4,1,2), f=Var(5,16,1), g=Var(6,16,0) ... OK

RMSE: tensor(0.1703, device='cuda:0')
NLL: (todo)



------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 21728410: <gp_jax> in cluster <dcc> Done

Job <gp_jax> was submitted from host <n-62-20-1> by user <pekra> in cluster <dcc> at Sun May 12 16:13:34 2024
Job was executed on host(s) <8*n-62-11-14>, in queue <gpuv100>, as user <pekra> in cluster <dcc> at Sun May 12 16:13:35 2024
</zhome/ab/b/200750> was used as the home directory.
</zhome/ab/b/200750/projects/project-lanczos-adjoints/matfree-extensions> was used as the working directory.
Started at Sun May 12 16:13:35 2024
Terminated at Sun May 12 16:42:51 2024
Results reported at Sun May 12 16:42:51 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
#BSUB -q gpuv100
#BSUB -J gp_jax
#BSUB -n 8
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -W 12:00
#BSUB -R "select[gpu32gb]"
#BSUB -R "rusage[mem=10GB]"
#BSUB -R "span[hosts=1]"
#BSUB -o gp_jax-40x-%J.out
#BSUB -e gp_jax-40x-%J.err

### Load the cuda module
module load cuda/12.4
source ../penv/bin/activate

time python experiments/applications/gaussian_process/error_metrics/gp_jax_test.py --name adjoints --seed 1 --num_data 40000 --rank_precon 500 --num_matvecs 10 --num_samples 5 --num_epochs 100 --num_partitions 200;
time python experiments/applications/gaussian_process/error_metrics/gp_keops_test.py --name gpytorch --seed 1 --num_data 40000 --rank_precon 500 --num_matvecs 10 --num_samples 5 --num_epochs 100 --cg_tol 1.;
time python experiments/applications/gaussian_process/error_metrics/gp_keops_test.py --name gpytorch3x --seed 1 --num_data 40000 --rank_precon 500 --num_matvecs 30 --num_samples 15 --num_epochs 100 --cg_tol 1e-2;

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1736.41 sec.
    Max Memory :                                 1337 MB
    Average Memory :                             1194.53 MB
    Total Requested Memory :                     81920.00 MB
    Delta Memory :                               80583.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                44
    Run time :                                   1766 sec.
    Turnaround time :                            1757 sec.

The output (if any) is above this job summary.



PS:

Read file <gp_jax-40x-21728410.err> for stderr output of this job.

